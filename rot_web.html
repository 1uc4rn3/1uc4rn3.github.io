<!DOCTYPE html><html>
<head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1">
<title>Root-of-Trust for Web E2EE</title>
<style type="text/css">
body{margin:40px auto;max-width:650px;line-height:1.6;font-size:18px;color:#444;padding:0 10px}
h1,h2,h3{line-height:1.2}
</style>
</head>
<body>
<header>
<h1>Root-of-Trust for Web E2EE</h1>
</header>

<h2>Problem:</h2>

The Web is generally considered to not have a sufficient root-of-trust for long-lived, sensitive E2EE software, specifically software where a long-lived identity key is stored.
The reason for the weaker security of E2EE web applications, when compared to mobile or desktop applications, is that the security of a web app is solely based on the TLS connection, and the entire app can be changed every time the web page is visited or reloaded.
On the other hand, mobile and desktop applications are generally signed either direcly by the OS vendor or by developer keys that are attested by the OS vendor, so that you know the app and any updates you receive were created by the developer, and that the developer is trusted to some degree by your OS.
This position I first remember hearing/seeing articulated in the "Security Cryptography Whatever" podcast and referenced web article"
<ul>
    <li><a href="https://securitycryptographywhatever.com/2023/11/07/PQXDH-etc/">Security Cryptography Whatever: Signal's Post-Quantum PQXDH, Same-Origin Policy, E2EE in the Browser Revisited</a></li>
    <li><a href="https://zfnd.org/so-you-want-to-build-an-end-to-end-encrypted-web-app/">So You Want to Build an End-to-End Encrypted Web App</a></li>
</ul>

On the other hand, it would be <i>really</i> useful if you could have an actually secure and trustworth root-of-trust for long-lived E2EE web apps.
Also, in a real have-your-cake-and-eat-it-too mood, I would love to have this without actually being dependent upon another authority, or at least not a single Big-Tech authority.
Ideally, I could publish software pseudoanonamously but in a way that you could securely know that I created it, and then have it attested to by multiple trusted third parties, without being directly dependent upon any of them.
The first step is to see if we can securly run software checked against a hash and then against a public key.
So let's see if we can do it!

<h2>Possible Approaches</h2>

<h3>Bookmarklet</h3>
<b>Idea:</b> Use a bookmarklet with a <code>data:</code> URL (<a href="https://developer.mozilla.org/en-US/docs/Web/URI/Reference/Schemes/data">MDN</a>) encoding a static webpage that fetches all resources (really all you need is JS) using Subresource Integrity (<a href="https://developer.mozilla.org/en-US/docs/Web/Security/Subresource_Integrity">MDN</a>).
This way, the base webpage would be constant, and then it would load all of it's resources using Subresource integrity which would check that they had not been modified by ensuring its hash matched the expected value.
<b>Problems:</b>
<ul>
    <li>The biggest issue is that <code>data:</code> URLs aren't considered secure contexts (<a href="https://developer.mozilla.org/en-US/docs/Web/Security/Secure_Contexts">MDN</a>).
    This prevents you from using any of the platform features that are restricted to secure contexts (<a href="https://developer.mozilla.org/en-US/docs/Web/Security/Secure_Contexts/features_restricted_to_secure_contexts">MDN list</a>), which is unfortunatly a deal-breaker for me, as I need Service Workers in order to proxy little web apps running in my E2EE system.
    </li>
</ul>
<h3>Browser Extension</h3>
<b>Idea:</b> Use a browser extension, which <i>does</i> count as a secure context, and we get to piggyback onto an existing app store ecosystem.
<b>Problems: (more unexplored)</b>
<ul>
    <li>The developer is dependent upon each app store for distribution to that browser's users</li>
    <li>Browser Extension stores don't have the best reputation anyway</li>
</ul>
<h3>view-source + Service Worker</h3>
<b>Idea:</b> Load a small webpage over TLS, tell the user to <code>view-source</code> and check that the contents match the expected contents (expected as attested to by others on blogs, Codeberg, GitHub, X, whatever).
Then, the user would press a tiny button that would load JS Service Worker attested to by Subresource Integrity.
The Service Worker would install itself, and from then on ensure that all fetched resources were expected and match the expected hash stored in the JS.
Then the question becomes how to prevent the browser from updating the main page or the service worker with a new version without it being checked.
Here I need to do experiments:
<ul>
    <li>Can the Service Worker be enforced by Subresource Integrity in all browsers? With a link with a preload? Firefox doesn't support subresource integrity in import maps, which otherwise <a href=https://shopify.engineering/shipping-support-for-module-script-integrity-in-chrome-safari">sounds great</a>.</li>
    <li>Can the static page be served by the Service Worker enforce Subresource Integrity for the new version of the Service Worker?</li>
    <li>Can the Service Worker <code>fetch</code> put the new Service Worker in the HTTP cache and check the Response headers to make sure that the cache is good for far into the future, and that the content matches the expected hash, and if it doesn't, delete the private data before it takes effect?</li>
</ul>
<b>Problems:</b>
<ul>
    <li>Checking <code>view-source</code> against an expected value is very cumbersome</li>
    <li>I need to do a lot of testing to see if this works reliably on all browsers</li>
</ul>

More to come, especially as I do these experiments.
<p>/1uc4rn3</p>
<p><a href="index.html">(back to index)</a></p>
</body>
</html>